{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Command Line Tools for Data Manipulation\n",
    "\n",
    "\n",
    "<img src=pics/command_line_fu.png /img>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><b> Leveraging Linux Shell Programs for Data Science Tasks</b></center>\n",
    "\n",
    "* Extraction in this field can be difficult. We are not just pulling data from a data base...\n",
    "\n",
    "* Skipping Extraction for now, let's focus on Transformation. \n",
    "\n",
    "* Storage we will touch on for small prototyping project only.\n",
    "\n",
    "<img src=pics/ETL_diagram.png /img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shell programs are written in C, are close to the Kernel and written in C.\n",
    "<div align=\"left\">\n",
    "<table style=\"width:25%\">\n",
    " <b>Authors</b>\n",
    "* Ken Thompson\n",
    "* Lee E. McMahon \n",
    "* Richard M. Stallman\n",
    "     \n",
    "\n",
    "Are you really going to write better, more robust, faster code than these people??\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<b>What Is The Command Line Good For ?</b>\n",
    "\n",
    "* Small data sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Imaginary use case: File Inventory\n",
    "\n",
    "For now, imagine we have a data file in CSV format with inventory information about\n",
    "a hard-drive.\n",
    "\n",
    "## basic inventory\n",
    "* number of files\n",
    "* size of volume\n",
    "* number of fiels by file-extension\n",
    "* lines of code in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "function count_lines\n",
    "{\n",
    "    input=$1\n",
    "    echo $(cat $input | wc -l)\n",
    "}\n",
    "\n",
    "function check_for_ascii\n",
    "{\n",
    "    input=$1\n",
    "    bool=$(file $input | grep -ic \"ascii\")\n",
    "    if [[ $bool -gt 0 ]];then\n",
    "        echo 1\n",
    "    else\n",
    "        echo 0\n",
    "    fi\n",
    "}\n",
    "\n",
    "function get_extension\n",
    "{\n",
    "    input=\"$1\"\n",
    "    base=$(basename \"$input\")\n",
    "    test_=$(echo \"$base\" | grep -c \"\\.\")\n",
    "\n",
    "    if [ $test_ -eq 0 ];then\n",
    "        echo \"NONE\"\n",
    "    else\n",
    "        ext=$(echo \"$base\" | rev | cut -d. -f 1 | rev)\n",
    "    fi\n",
    "\n",
    "    echo ${ext}\n",
    "}\n",
    "\n",
    "#### calls here ###\n",
    "input=$1\n",
    "\n",
    "count=$(count_lines $input)\n",
    "ascii_bool=$(check_for_ascii $input)\n",
    "ext=$(get_extension $input)\n",
    "\n",
    "if [ $ascii_bool == 1 ];then\n",
    "    printf \"\\\"${input}\\\",\\\"${count}\\\",\\\"${ext}\\\"\\n\"\n",
    "else\n",
    "    printf \"\\\"{$input}\\\",\\\"0\\\",\\\"${ext}\\\"\\n\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/notebooks/orbital\"\n",
    "export PATH=$PWD:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418M\ttotal\r\n"
     ]
    }
   ],
   "source": [
    "du -h -c linux-2.6.32.67 | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t5m37.544s\r\n",
      "user\t2m18.962s\r\n",
      "sys\t4m50.221s\r\n"
     ]
    }
   ],
   "source": [
    "#make a header\n",
    "printf \"\\\"path\\\",\\\"nlines\\\",\\\"ext\\\"\\n\" > $root_dir/linux_inventory.csv\n",
    "# run inventory program on files \n",
    "time find $root_dir/linux-2.6.32.67 -type f | xargs -n 1 $root_dir/make_inventory.sh >> $root_dir/linux_inventory_local_path.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30,485\r\n"
     ]
    }
   ],
   "source": [
    "cat $root_dir/linux_inventory_local_path.csv | wc -l | thou_comma.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebooks/orbital/linux-2.6.32.67/net/wireless/ibss.c\"                 \"509\"   \"c\"\r\n",
      "notebooks/orbital/linux-2.6.32.67/net/wireless/scan.c\"                 \"1027\"  \"c\"\r\n",
      "notebooks/orbital/linux-2.6.32.67/net/wireless/lib80211_crypt_tkip.c\"  \"788\"   \"c\"\r\n",
      "notebooks/orbital/linux-2.6.32.67/net/wireless/util.c\"                 \"717\"   \"c\"\r\n",
      "notebooks/orbital/linux-2.6.32.67/net/wireless/nl80211.c\"              \"4896\"  \"c\"\r\n"
     ]
    }
   ],
   "source": [
    "head -n 5 \"${root_dir}/linux_inventory_local_path.csv\" | cut -d/ -f 7- | column -t -s,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What if we want to change the root path in the inventory files ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/home/daniel/git/Python2.7/DataScience/notebooks/orbital/linux-2.6.32.67/net/wireless/ibss.c\",\"509\",\"c\"\r\n"
     ]
    }
   ],
   "source": [
    "head -n 1 $root_dir/linux_inventory_local_path.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linux-2.6.32.67/net/wireless/ibss.c\r\n"
     ]
    }
   ],
   "source": [
    "head -n 1 $root_dir/linux_inventory_local_path.csv | cut -d, -f 1 | sed 's/\\\"//g' | cut -d/ -f 9-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/sandbox/orbital_slides/linux-2.6.32.67/net/wireless/ibss.c\",\"509\",\"c\"\r\n"
     ]
    }
   ],
   "source": [
    "new_path=\"/work/sandbox/orbital_slides/\"\n",
    "head -n 1 $root_dir/linux_inventory_local_path.csv | sed 's/\\\"//1' |  cut -d/ -f 9- | sed \"s#^#$new_path#g\"   # need to change the sed sep to '#' bc path has '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"/work/sandbox/orbital_slides/linux-2.6.32.67/net/wireless/ibss.c\",\"509\",\"c\"\r\n"
     ]
    }
   ],
   "source": [
    "head -n 1 $root_dir/linux_inventory_local_path.csv | sed 's/\\\"//1' |  cut -d/ -f 9- | sed \"s#^#$new_path#g\" | sed 's/^/\\\"/1' # need to change the sed sep to '#' bc path has '/'sed 's/^/\\\"/1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Types Of File Are Present ? : Sort by extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    857 \"txt\"\r\n",
      "   1080 \"S\"\r\n",
      "   2818 \"NONE\"\r\n",
      "  11638 \"h\"\r\n",
      "  13154 \"c\"\r\n"
     ]
    }
   ],
   "source": [
    "cat $root_dir/linux_inventory.csv | cut -d, -f 3 | sort | uniq -ic | sort -n | tail -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##GNU Parallel\n",
    "\n",
    "Run shell scripts and/or commands ( which are really C programs ) in parallel from a terminal.\n",
    "\n",
    "*Documentation*\n",
    "<url>https://www.gnu.org/software/parallel/parallel_tutorial.html#The-7-predefined-replacement-strings</url>\n",
    "\n",
    "Good examples of using advanced features of *parallel*\n",
    "<url>https://www.biostars.org/p/63816/</url>\n",
    "\n",
    "I used to work with brain imaging, and a common task is to extract the brain from the skull with Brain Extraction Tool (BET).\n",
    "BET is a complex monster that uses Naive Bayes and a brain atlas. It runs fairly quick for one brain, but here we need to run it on 210 seperate images.\n",
    "\n",
    "BACKGROUND:\n",
    "In order to register the anatomic image (T1 weighted high res) to the lower res BOLD image, the mean of the time series is taken.\n",
    "But, the single volume frames should first be extracted from the skull, because the skull has few features to match.\n",
    "\n",
    "* extract brain from every (210) BOLD volume\n",
    "* Motion Correct, (register the brain volumes to each other)\n",
    "* Make a mean image for registration ( T1 is registered to the BOLD mean and resampled)\n",
    "\n",
    "Running BET on 210 images in serial takes a long time and is annoying when you are working fast.\n",
    "\n",
    "## Time Command\n",
    "<url>http://stackoverflow.com/questions/556405/what-do-real-user-and-sys-mean-in-the-output-of-time1</url>\n",
    "\n",
    "* Real is wall clock time - time from start to finish of the call. This is all elapsed time including time slices used by other processes and time the process spends blocked (for example if it is waiting for I/O to complete).\n",
    "\n",
    "* User is the amount of CPU time spent in user-mode code (outside the kernel) within the process. This is only actual CPU time used in executing the process. Other processes and time the process spends blocked do not count towards this figure.\n",
    "\n",
    "* Sys is the amount of CPU time spent in the kernel within the process. This means executing CPU time spent in system calls within the kernel, as opposed to library code, which is still running in user-space. Like 'user', this is only CPU time used by the process. See below for a brief description of kernel mode (also known as 'supervisor' mode) and the system call mechanism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t1m15.517s\r\n",
      "user\t8m57.207s\r\n",
      "sys\t0m10.395s\r\n"
     ]
    }
   ],
   "source": [
    "in_path=\"/home/daniel/git/Python2.7/DataScience/notebooks/orbital/bold_split/original_split\"\n",
    "out_path=\"/home/daniel/git/Python2.7/DataScience/notebooks/orbital/bold_split/bet\"\n",
    "\n",
    "time parallel --jobs 8 \"bet {} $out_path/{#}vol_bet\" :::  $in_path/vol*.nii.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100vol_bet.nii.gz\r\n",
      "101vol_bet.nii.gz\r\n",
      "102vol_bet.nii.gz\r\n"
     ]
    }
   ],
   "source": [
    "ls $out_path | head -n 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Blood oxygenation level dependent (BOLD) image: \n",
    "### With Skull and Scalp (Before) and After Extraction AKA Skull Stripping (After)\n",
    "<img src=pics/bf_and_after_bold_bet_masked.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Run Inventory With Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "real\t1m46.358s\r\n",
      "user\t4m39.934s\r\n",
      "sys\t6m7.481s\r\n"
     ]
    }
   ],
   "source": [
    "time find $root_dir/linux-2.6.32.67 -type f | parallel -n 1 --jobs 8 'make_inventory.sh' >> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Use Case: File System Manipulation And Quick Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# become root and run \n",
    "# free && sync && echo 3 > /proc/sys/vm/drop_caches && free\n",
    "time find \"${root_dir}/linux-2.6.32.67\" -maxdepth 2 -mindepth 1 -type f -name \"*.c\" |  parallel --jobs 8 -n 1 'pcregrep -no \"(?sm)if\\s*\\(.*?\\)\" /dev/null' | sed 's/\\s//g' > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#FIFO For Moving Data\n",
    "This is my question on SO and the answer is nice: <url> http://stackoverflow.com/questions/30688178/maintaining-a-fifo-readable-across-different-executions </url>\n",
    "\n",
    "\n",
    "* mkfifo \\$root_dir/pipe\n",
    "* cat > \\$root_dir/pipe &\n",
    "    * get pid\n",
    "* run inventory wit output to pipe\n",
    "* kill cat with pid\n",
    "\n",
    "NOTE: Terminate cat *kill -HUP $pid* before ending mySQL load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "mkfifo $root_dir/pipe\n",
    "cat > $root_dir/pipe\n",
    "pid=$(echo $!)\n",
    "echo $pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mysqladmin --user=root --password=test create LinuxInventory\n",
    "csvsql --db \"mysql://root:test@127.0.0.1/LinuxInventory\" --tables \"Inventory\" --insert pipe \n",
    "#\"${root_dir}/linux_inventory.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Check that it worked\n",
    "\n",
    "The notebook isn't using the alias the way I expected so I had to type out the full command with user and password.\n",
    "In normal practice you'd make an alias as in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\r\n",
      "| ext  | COUNT(ext) |\r\n",
      "+------+------------+\r\n",
      "| c    |      13154 |\r\n",
      "| h    |      11639 |\r\n",
      "| S    |       1080 |\r\n",
      "| txt  |        857 |\r\n",
      "| dts  |        115 |\r\n",
      "+------+------------+\r\n"
     ]
    }
   ],
   "source": [
    "alias mysql='mysql --user=root --password=test'\n",
    "mysql -e \"SELECT ext, COUNT(ext) FROM inventory GROUP BY ext ORDER BY COUNT(ext) DESC LIMIT 5;\" LinuxKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Working With Data Base ( for small data exploration )\n",
    "\n",
    "I keep a mySQL and Mongo DB on my laptop for various experiments and local programming but it's also great to lean on sqlite for small command line driven exploratory exercises.\n",
    "\n",
    "This way I can easily version and share the complete workflow.\n",
    "\n",
    "Python and R have database connection layers, but sometimes you just want a csv without any additional platform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dts  115\r\n",
      "txt  857\r\n",
      "S    1080\r\n",
      "h    11639\r\n",
      "c    13154\r\n"
     ]
    }
   ],
   "source": [
    "query=\"select ext, count(ext) from inventory group by ext order by count(ext);\"\n",
    "sql2csv --db mysql://root:test@127.0.0.1/LinuxKernel --query \"${query}\" | tail -n 5 | column -t -s, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26845\r\n"
     ]
    }
   ],
   "source": [
    "# paste:   -s  --serial    -d --delimiter\n",
    "sql2csv --db mysql://root:test@127.0.0.1/LinuxKernel --query \"${query}\" | tail -n 5 | cut -d, -f 2 | paste -s -d+ | bc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Map Reduce Via MRJob and Shell Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runners:\r\n",
      "  emr:\r\n",
      "    aws_access_key_id: ******\r\n",
      "    aws_secret_access_key: ******\r\n",
      "    ec2_key_pair: Example\r\n",
      "    ec2_key_pair_file: ~/.ssh/Example.pem\r\n",
      "    python_bin: python2.7\r\n",
      "    strict_protocols: true\r\n",
      "    bootstrap:\r\n",
      "    - sudo python2.7 -m pip install mrjob\r\n",
      "\r\n",
      "  hadoop:\r\n",
      "    strict_protocols: true\r\n",
      "  inline:\r\n",
      "    strict_protocols: true\r\n",
      "  local:\r\n",
      "    strict_protocols: true\r\n"
     ]
    }
   ],
   "source": [
    "cat ~/.mrjob.conf | sed  's/\\(aws_.*:\\s*\\)\\(.*$\\)/\\1******/g'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from mrjob.job import MRJob\n",
    "from mrjob.util import bash_wrap\n",
    "\n",
    "class Grep(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        yield line.split(',')[0]\n",
    "        \n",
    "    def reducer(self, _, line):\n",
    "        return bash_wrap(\"pcregrep -no \"(?sm)if\\s*\\(.*?\\)\" /dev/null' | sed 's/\\s//g'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordFrequencyCount.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Helpful Custom Shell Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin\r\n",
      "/home/daniel/anaconda/bin\r\n",
      "/home/daniel/anaconda/envs/py27/bin\r\n",
      "/home/daniel/bin\r\n",
      "/home/daniel/FSL\r\n",
      "/home/daniel/spark-1.5.2-bin-hadoop2.6/bin\r\n",
      "/home/daniel/spark-1.5.2-bin-hadoop2.6/sbin\r\n",
      "/opt/afni_bin/linux_xorg7_64\r\n",
      "/sbin\r\n",
      "/usr/bin\r\n",
      "/usr/games\r\n",
      "/usr/lib/cmtk/bin/\r\n",
      "/usr/lib/fsl/5.0\r\n",
      "/usr/local/bin\r\n",
      "/usr/local/sbin\r\n",
      "/usr/sbin\r\n"
     ]
    }
   ],
   "source": [
    "function pp\n",
    "# script to pretty print variables in a easy to read list \n",
    "\n",
    "{\n",
    "    var=$1\n",
    "    echo $var | sed 's/:/\\n/g' | sort | uniq\n",
    "}\n",
    "\n",
    "pp $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links\n",
    "\n",
    "* http://www.commandlinefu.com/commands/browse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
