{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line Tools for Small Data\n",
    "\n",
    "\n",
    "<img src=http://imgs.xkcd.com/comics/command_line_fu.png /img>\n",
    "\n",
    "\n",
    "Ipython run in a terminal is about the best way to work with data interactively. Loading a csv into a Pandas dataframe or just a Numpy array is very powerful. However, there are times when  a handful of shell programs can either save the day or just make the day more productive.\n",
    "\n",
    "Primarliy, I've found the program <i>find</i> to be extremely helpful, and combing it with <i>grep / pcregrep</i> can be enough to get a report out. \n",
    "\n",
    "I also find myself loading data into a table on mySQL as the size of the test data grows. This has the advantage of being a little easier to share with coworkers too.\n",
    "\n",
    "Csvkit was brought to my attention by the O'Reilly book, <u>Data Science on the Command Line</u> and I've come to really like it for small scale work. Pandas can also push and pull data into and out of tables. \n",
    "\n",
    "There are times when keeping my preliminary preprocessing steps completely shell driven is convenient especially if used with a makefile. I've been exploring the use of Drake, since it can encorporate native Python and I think that will be the future. Since GNU Make has been around a long time and is typically installed on any machine you're likely to come across, I've been trying to use it more and appreciate it before making the switch to Drake.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programs you may want to install\n",
    "* csvkit by onryx, install with pip or conda\n",
    "* pcregrep, Debian sudo apt-get install\n",
    "* parallel, in the Debian repo.\n",
    "\n",
    "## Other items\n",
    "I do a little contrast using Python and Pandas. You can skip running it if you don't already have it installed.\n",
    "\n",
    "* mySQL\n",
    "* Pandas\n",
    "\n",
    "## Links\n",
    "* regular expression: http://www.rexegg.com/\n",
    "* freeing memory: http://unix.stackexchange.com/questions/87908/how-do-you-empty-the-buffers-and-cache-on-a-linux-system\n",
    "* csvkit: https://csvkit.readthedocs.org/en/0.9.1/\n",
    "* _find_ command examples http://www.binarytides.com/linux-find-command-examples/\n",
    " * stackoverflow on excluding directories with _find_ http://stackoverflow.com/questions/1489277/how-to-use-prune-option-of-find-in-sh\n",
    "* fun site for inspiration http://www.commandlinefu.com/commands/browse\n",
    "\n",
    "# How to use this notebook\n",
    "The ipython notebook is great for Python and there's some support for BASH and SQL. However, it's not perfect yet, and you will have to modify some lines.\n",
    "\n",
    "The cells using bash commands, have the bash magic at the top and a shell variable:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "root=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That path is specific to my personal computer and will not work for you. You will need to change **every** occurance to the root path you downloaded the data set to.\n",
    "\n",
    "In the future I'll consider using this BASH kernel for ipython notebooks:\n",
    "https://github.com/takluyver/bash_kernel. This kernel would allow me to export any shell variables once. \n",
    "\n",
    "I also like this SQL magic provided here: \n",
    "https://github.com/catherinedevlin/ipython-sql\n",
    "\n",
    "It prints SQL tables nicely and could be good for work reports based on SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook doesn't explain the individual commands in great detail. I am assuming that you either know them, or will be researching them on your own as you work through the commands. I have made some effort to make limited notes about the commands you see. Mainly, these notes are for explaining something not easily understood right away although I still assume you have googled or man paged the command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Man Page\n",
    "If you are very new to the command line you might not know how the man pages work.\n",
    "The manual is opened in vi like environment so navigation might be difficult at first.\n",
    "Pressing _h_ while in the man pages will bring up a help file.\n",
    "\n",
    "Here is summary of a few commands for the man page viewer:\n",
    "* q to quit\n",
    "* / to search\n",
    "* n for next forward match\n",
    "* N for match backwards\n",
    "* h  man page navigation help\n",
    "* j scroll up\n",
    "* k scroll down\n",
    "\n",
    "# Things I Don't Cover\n",
    "## Quoting\n",
    "Quoting is tricky when dealing with the shell. The shell has to interpret ( or not ) everything passed in the command line. That means if there's spaces, or special tokens in the strings you are passing around, you'll have to escape the strings and wrap them in quotes, double or single.\n",
    "\n",
    "This is a topic in itself. I didn't want to get sidetracked here so please read about it. In fact you'll have to\n",
    "because you'll end up banging your head against a wall sooner than later because of it.\n",
    "\n",
    "A nice work around, is to write intermediate steps of a shell script to a file. Then read back the file. Since you are not passing the strings through the shell interpreter directly through stdin, they will not need special escaping or treatment. There's nothing wrong with this, it can help make things more clear to others, rather than using obscure escape sequences.\n",
    "\n",
    "I made a point to use only _nice_ file names here. Windoze people have a nasty habit of using spaces which is a huge PITA.\n",
    "\n",
    "### In brief:\n",
    "1. Single quotes, ' , are for string literals with no special actions due to tokens\n",
    "2. Double quotes, \" , allow the expansion of shell variables and parameters, \\$FOO, and \\\\ escape charaters\n",
    "3. back ticks, ` , are completely different and are used to evaluate a command. Although I prefer the \\$(cmd) syntax\n",
    "\n",
    "## Regular Expressions\n",
    "\n",
    "I used a handful of beefy regex's here that I chose because they cover a lot of ground. You'll want to spend a few weekends on the regegg.com site. I provide a quick overview of what the regex means in a cell but you'll have to\n",
    "look them up yourself. \n",
    "\n",
    "https://en.wikiquote.org/wiki/Jamie_Zawinski\n",
    "\n",
    "\"Some people, when confronted with a problem, think \"I know, I'll use regular expressions.\" Now they have two problems.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Imaginary use case\n",
    "\n",
    "I'm given a hard drive full of source code and told that we will be doing a dependency analysis for some particular C libraries. We don't know in advance what we are looking for at the moment. That may be revealed on a client call or more information will be passed down. For now, we have the directories what can we do with it quickly  ?\n",
    "\n",
    "For this exercise I'm using the Linux Kernel 2.6 because it's sufficiently large and free to download.\n",
    "\n",
    "####The first thing I'd do, is inventory this thing we are given and prepare some basic report about what we have been given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##For this exercise we need an inventory\n",
    "\n",
    "Below is is a simple inventory shell script, where we get the lines of code (including blanks, comments everything...not a real good method)\n",
    "and the file extension. This is more advanced than I plan to cover in this notebook. \n",
    "\n",
    "This code goes into a file named run_inventory.sh which is included in the git repo if you cloned it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: #: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash # this line is here for syntax highlighting only\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "function count_lines\n",
    "{\n",
    "    input=$1\n",
    "    echo $(cat $input | wc -l)\n",
    "}\n",
    "\n",
    "function check_for_ascii\n",
    "{\n",
    "    input=$1\n",
    "    bool=$(file $input | grep -ic \"ascii\")\n",
    "    if [[ $bool -gt 0 ]];then\n",
    "        echo 1\n",
    "    else\n",
    "        echo 0\n",
    "    fi\n",
    "}\n",
    "\n",
    "function get_extension\n",
    "{\n",
    "    input=\"$1\"\n",
    "    base=$(basename \"$input\")\n",
    "    test_=$(echo \"$base\" | grep -c \"\\.\")\n",
    "\n",
    "    if [ $test_ -eq 0 ];then\n",
    "        echo \"NONE\"\n",
    "    else\n",
    "        ext=$(echo \"$base\" | rev | cut -d. -f 1 | rev)\n",
    "    fi\n",
    "\n",
    "    echo ${ext}\n",
    "}\n",
    "\n",
    "#### calls here ###\n",
    "input=$1\n",
    "\n",
    "count=$(count_lines $input)\n",
    "ascii_bool=$(check_for_ascii $input)\n",
    "ext=$(get_extension $input)\n",
    "\n",
    "if [ $ascii_bool == 1 ];then\n",
    "    printf \"\\\"${input}\\\",\\\"${count}\\\",\\\"${ext}\\\"\\n\"\n",
    "else\n",
    "    printf \"\\\"{$input}\\\",\\\"0\\\",\\\"${ext}\\\"\\n\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Make an inventory\n",
    "The _find_ program is tricky to learn, it has many options. I plan to dive more into _find_, but for now, I really just want an inventory.csv to play with. \n",
    "\n",
    "I give find the path to search, which is our Linux Kernel directory, then I tell find, to only return the type, \"f\" which means files. No directories. \n",
    "\n",
    "I then use a pipe '|' to pass the output into the input of the next program 'run\\_inventory.sh'. We need to use _xargs_ to limit the way the output is presented to 'run\\_inventory.sh'. _Xargs_ is another topic to learn about, so for now, just trust me. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "#make a header\n",
    "printf \"\\\"path\\\",\\\"nlines\\\",\\\"ext\\\"\\n\" > $root/linux_inventory.csv\n",
    "find $root/linux-2.6.32.67 -type f | xargs -n 1 $root/make_inventory.sh >> $root/linux_inventory.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The > is for stream redirection. The output stream from _printf_ is sent to a new file. This will clobber existing files so practice with it. The second use is slightly different, >> is an appending stream redirection.\n",
    "\n",
    "Since we don't want to clobber the linux_inventory.csv, we use the append operation for the actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's useful to be able to dro the header and add it back. You could do it in an editor, but since this notebook needs to be self contained, I add these cells. plus you can see another use for _sed_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#drop header\n",
    "root=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "sed -i '1 d' $root/linux_inventory.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# add header \n",
    "\n",
    "root=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "header=\"\\\"path\\\",\\\"nlines\\\",\\\"ext\\\"\"\n",
    "sed -i \"1 i ${header}\" $root/linux_inventory.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"path\",\"nlines\",\"ext\"\n",
      "\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/scan.c\",\"1027\",\"c\"\n",
      "\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/core.h\",\"401\",\"h\"\n",
      "\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/ibss.c\",\"509\",\"c\"\n",
      "\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/nl80211.c\",\"4896\",\"c\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "head -n 5 \"${root_dir}/linux_inventory.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neat trick to view the csv contents better. Works great in a real terminal, the ipython notebook's default cell width is too small to look nice :|  So I hacked off part of the path output.\n",
    "\n",
    "https://www.reddit.com/r/IPython/comments/27zash/can_i_increase_notebook_cell_width_on_wide_screens/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"path\"                                                                                            \"nlines\"  \"ext\"\n",
      "Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/scan.c\"                 \"1027\"    \"c\"\n",
      "Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/core.h\"                 \"401\"     \"h\"\n",
      "Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/ibss.c\"                 \"509\"     \"c\"\n",
      "Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/nl80211.c\"              \"4896\"    \"c\"\n",
      "Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/lib80211_crypt_tkip.c\"  \"788\"     \"c\"\n",
      "Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/util.c\"                 \"717\"     \"c\"\n",
      "Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/mlme.c\"                 \"679\"     \"c\"\n",
      "Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/reg.h\"                  \"55\"      \"h\"\n",
      "Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/wext-sme.c\"             \"402\"     \"c\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "head -n 10 \"${root_dir}/linux_inventory.csv\" | cut -d/ -f 5- | column -t -s,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipe, |, takes output from another process, and supplies it as input to the next program.\n",
    "You will get different output for the two cells below. The first cell tells _grep_ to operate on the output stream of the _find_ command. The second tells _grep_ to operate on files whose path is given as the output from _find_. \n",
    "\n",
    "If you don't know what or how _head_ works, try the man page for it. Look up the option _n_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/virt/kvm/ioapic.h\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/virt/kvm/irq_comm.c\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/virt/kvm/iodev.h\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/virt/kvm/coalesced_mmio.h\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/virt/kvm/coalesced_mmio.c\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/virt/kvm/Kconfig\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/virt/kvm/iommu.c\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/virt/kvm/eventfd.c\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/COPYING\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "find $root/linux-2.6.32.67 -type f | grep \"2.6\" | tail -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README:   not incremental and must be applied to the 2.6.xx base tree. For\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README:   example, if your base kernel is 2.6.12 and you want to apply the\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README:   2.6.12.3 patch, you do not and indeed must not first apply the\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README:   2.6.12.1 and 2.6.12.2 patches. Similarly, if you are running kernel\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README:   version 2.6.12.2 and want to jump to 2.6.12.3, you must first\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README:   reverse the 2.6.12.2 patch (that is, patch -R) _before_ applying\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README:   the 2.6.12.3 patch.\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README:   Compiling and running the 2.6.xx kernels requires up-to-date\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README:     kernel source code:\t/usr/src/linux-2.6.N\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/README:   cd /usr/src/linux-2.6.N\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "find $root/linux-2.6.32.67 -type f | xargs grep \"2.6\" | tail -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's make a summary of the kinds of files we were given by extension.\n",
    "\n",
    "The next three cells are illustrating the how one can use <i>cat, cut, sort and uniq</i> to get a preliminary output of this inventory.\n",
    "\n",
    "I broke out the steps so that you can follow along. There maybe short cuts and other arguments I didn't use. Sometimes it doesn't matter if you do something the correct way, just that you get it done quickly and you are confident that you know what you did. This type of prototyping is great, because you can see what's happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The program <i> cut </i> is super helpful. We can parse many output streams with <i>cut</i>.\n",
    "If the format of a steam in tablular, then <i>awk</i> maybe the best, but <i>awk</i> is a whole animal into itself and I think most days, I rely on <i>cut</i> and then step into ipython and use Pandas or just Numpy.\n",
    "\n",
    "The <i>-d,</i> option is to set the delimiter and the <i>-f 3</i> says to use the 3rd field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"NONE\"\n",
      "\"c\"\n",
      "\"c\"\n",
      "\"NONE\"\n",
      "\"NONE\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "cat $root_dir/linux_inventory.csv | cut -d, -f 3 | tail -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"y\"\n",
      "\"y\"\n",
      "\"y\"\n",
      "\"y\"\n",
      "\"ymfsb\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "cat \"${root_dir}/linux_inventory.csv\" | cut -d, -f 3 | sort  | tail -n  5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1 \"x86\"\n",
      "    105 \"xml\"\n",
      "      6 \"xsl\"\n",
      "      5 \"y\"\n",
      "      1 \"ymfsb\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "cat \"${root_dir}/linux_inventory.csv\" | cut -d, -f 3 | sort | uniq -c | tail -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    857 \"txt\"\n",
      "   1080 \"S\"\n",
      "   2818 \"NONE\"\n",
      "  11638 \"h\"\n",
      "  13154 \"c\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "cat $root_dir/linux_inventory.csv | cut -d, -f 3 | sort | uniq -ic | sort -n | tail -n 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting this command line data into a database.\n",
    "* csvkit: csvsql\n",
    "* Pandas:  df.to_sql()\n",
    "\n",
    "\n",
    "### Both Pandas and csvkit use SqlAlchemy to handle the connection to the DB. \n",
    "\n",
    "I'm not expert at SqlAlchemy, but learning the connection strings offer value immediately."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "That's the, \"mysql://<log-in>:<passwd>@<ip>/<db-name>\"  I'm running mySQL locally, localhost has IP 127.0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'll make the database using the mysqladmin program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u0007mysqladmin: CREATE DATABASE failed; error: 'Can't create database 'LinuxKernel'; database exists'\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "root=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "mysqladmin --user=root --password=test create LinuxKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csvsql will put the data into a table named \"inventory\" or if no --tables argument is given, named after the input file. It also deduces the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "root=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "csvsql --db \"mysql://root:test@127.0.0.1/LinuxKernel\" --tables \"inventory\" --insert \"${root}/linux_inventory.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that it worked\n",
    "\n",
    "The notebook isn't using the alias the way I expected so I had to type out the full command with user and password.\n",
    "In normal practice you'd make an alias as in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1146 (42S02) at line 1: Table 'LinuxKernel.inventory' doesn't exist\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#alias mysql='mysql --user=root --password=test'\n",
    "#mysql -e \"SELECT * FROM inventory LIMIT 5;\" LinuxKernel\n",
    "\n",
    "mysql --user=root --password=test -e \"SELECT * FROM inventory LIMIT 5;\" LinuxKernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV outputs from mySQL without stepping into the sql shell\n",
    "sql2csv returns a query in csv format to the stdout which can then be redirected to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dts  115\n",
      "txt  857\n",
      "S    1080\n",
      "h    11639\n",
      "c    13154\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sql2csv --db mysql://root:test@127.0.0.1/LinuxKernel --query \"select ext, count(ext) from inventory group by ext order by count(ext);\" | \\\n",
    "    tail -n 5 | column -t -s, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The numbers checkout.\n",
    "\n",
    "#### Lets explore <i>awk</i> a little. The easiest thing to make _awk_ do (and perhaps the most useful), is to print columns or rows from a file stream.\n",
    "\n",
    "<i>awk</i>\n",
    "* FS field separator set to comma\n",
    "* $3 is the 3rd column\n",
    "\n",
    "<i>grep</i>\n",
    "* -E regular expression\n",
    "* -c count occurance (grep operates per line, we use pcregrep for multiple line searches)\n",
    "\n",
    "There is a way to do the whole regex and count in <i>awk</i> I just didn't want to get into it. I'm still learning <i>awk</i> myself, and I haven't decided on it's usefulness over other tools. If I'm already in a database then forget it...I mostly want to show use of <i>grep</i> and <i>awk</i> for column parsing ( rather than cut )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1715\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "cat \"${root_dir}/linux_inventory.csv\"  | awk  'FS=\",\"; {print $3}' | grep -cE \"txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice using _find_ and _grep_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "find \"${root_dir}/linux-2.6.32.67\" -maxdepth 2 -mindepth 1 -type f -iname \"*.c\" | \\\n",
    "    xargs -n 1 pcregrep -no \"(?sim)[a-z]+\\w*\\(.*?\\)\" /dev/null | \\\n",
    "    sed 's/\\s//g' | \\\n",
    "    tail -n 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find \\${root_dir}/linux-2.6.32.67\" -maxdepth 2 -mindepth 1 -type f -iname \"*.c\"\n",
    "\n",
    "* path to search\n",
    "* -maxdepth 2 dont', search past 2 directories deep\n",
    "* -mindepth 1, search at least 1 directory deep   (using this to save time and the notebook kept crashing)\n",
    "* -type f, only look for files not directories or links or anything else\n",
    "* -iname,  case insensitive glob style name matching, just like <i>ls</i> uses\n",
    "\n",
    "## xargs\n",
    "A neat helper program, that takes the output from another shell program, and parses it into discrete intput arguments for the next program in a pipe.\n",
    "\n",
    "This will allow us to pass one line at a time from find, to grep. Some programs do not need xargs, as they are designed to take a stream of input. Not in this case however.\n",
    "\n",
    "## pcregrep -no \"(?sim)[a-z]+\\w*\\(.*?\\)\" /dev/null\n",
    "We also introduct, <i>Pearl Compatiple Regular Expression Grep (pcregrep)</i>. \n",
    "The <i>(?sim)</i> are options:\n",
    "\n",
    "* s dot matches everything including newlines \"\\n\"\n",
    "* i case insensitive\n",
    "* m multiline\n",
    "\n",
    "The <i>(.*?)</i> makes the greedy \".\" stop, after encountering a left parenthesis, escaped like this \\\\( \n",
    "This page explains the \"Lazy Trap\" issue, where the .*? contron on the greedy match \"jumps the fence\"\n",
    "http://www.rexegg.com/regex-quantifiers.html#lazytrap\n",
    "\n",
    "### This is going to hunt for functions\n",
    "That is, strings that match (?sim)[a-z]+\\w*\\(.*?\\), where:\n",
    "\n",
    "* [a-z] a list of lower case letters\n",
    "* '+' at least once, or more\n",
    "* \\w any alpha-numeric zero or more times\n",
    "* \\\\( literal left parenthesis\n",
    "* greedy match until right paren\n",
    "\n",
    "The <i>/dev/null</i> is a trick to make grep print the file path it's working on.\n",
    "\n",
    "## sed \n",
    "used to remove any spaces:\n",
    "sed 's/\\s//g'\n",
    "\n",
    "* s  substitute\n",
    "* \\s  regular expression for any kind of while space\n",
    "* //  replace with nothing....easier to read if it was, sed 's/foo/bar/g' , replace 'foo' with 'bar'\n",
    "* g globally, as many times as a match can be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "find \"${root_dir}/linux-2.6.32.67\" -maxdepth 2 -mindepth 1 -type f -iname \"*.c\" | xargs -n 1 pcregrep -no \"(?sim)[a-z]+\\w*\\(.*?\\)\" /dev/null | sed 's/\\s//g' | tail -n 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This example used the regular expression syntax where as above, I used the \"globbing\" rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "find \"${root_dir}/linux-2.6.32.67\" -maxdepth 2 -mindepth 1 -type f -regextype posix-extended -regex \".*\\.(c|h|cpp)\" | \\\n",
    "    xargs -n 1 pcregrep  -no \"(?sim)[a-z]+\\w*\\(.*?\\)\" /dev/null | sed 's/\\s//g' | tail -n 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use the \"or\" operator (-o)  to _find_ as well as the regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "find \"${root_dir}/linux-2.6.32.67\" -maxdepth 2 -mindepth 1 -type f -iname \"*.c\" -o -iname \"*.h\" -o -iname \"*.cpp\" | tail -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An aside about loops vs the _parallel_ program\n",
    "## While loops in bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "while read f;do   \n",
    "    file_=$(echo $f | cut -d, -f 1 | sed 's/\\\"//g')\n",
    "    grep -Eo -m 1 \"^#include <linux\"  \"${file_}\" /dev/null\n",
    "done < \"${root_dir}/linux_inventory.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "cat $root_dir/prep.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "tail -n 10 \"${root_dir}/linux_inventory.csv\" | xargs -P 4 -n 1 $root_dir/prep.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <i>Parallel</i>\n",
    "\n",
    "A powerful program that makes running shell programs on multiple cores trivial, is <i>parallel</i> .\n",
    "It also cleans up code and makes things a single line when used with just a single core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Free the cache to really test the timing\n",
    "# become root and run \n",
    "# free && sync && echo 3 > /proc/sys/vm/drop_caches && free\n",
    "\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "time find \"${root_dir}/linux-2.6.32.67\" -maxdepth 2 -mindepth 1 -type f -name \"*.c\" | \\\n",
    "    parallel --jobs 1 -n 1 'pcregrep -no \"(?sm)if\\s*\\(.*?\\)\" /dev/null' | sed 's/\\s//g' > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# become root and run \n",
    "# free && sync && echo 3 > /proc/sys/vm/drop_caches && free\n",
    "time find \"${root_dir}/linux-2.6.32.67\" -maxdepth 2 -mindepth 1 -type f -name \"*.c\" | \\\n",
    "    parallel --jobs 4 -n 1 'pcregrep -no \"(?sm)if\\s*\\(.*?\\)\" /dev/null' | sed 's/\\s//g' > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend our use case\n",
    "## Add categorical columns to our inventory database\n",
    "Let's say that we want to add a categorical columns to our SQL table. This is a nice way to store information about a table without worrying about normalization. We are not DBA's trying to maintain strict schema here. We just need a fast and intuitive way to query our data.\n",
    "\n",
    "I had some difficulty when I first started reading about categorical variables. They are writen and talked about in various contexts. For now, I'm thinking about a column in a database table, that contains a string, which describes the row.\n",
    "\n",
    "In contrast, I could have had a boolean flag like column. For every file with an include statement that has \"linux\" in it, give it a 1 and the rest a 0. Then for another condition, I'd have to add a flag for it, \"foo\" with 1 and 0's and so on. \n",
    "\n",
    "In this case, a categorical variable is a single column that makes it wasy to do \"group by\", and aggregrate across categories. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So let's add a column for the name of the directory,in the include statement, \"#include <linux/*>\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "find $root_dir/linux-2.6.32.67 -type f -iname \"*.c\" -o -iname \"*.h\" | \\\n",
    "    parallel -n 1 --jobs 4 'grep -Po -m 1 \"(#include\\s*\\Wlinux/)\\K\\w+\"' /dev/null \\\n",
    "    > \"${root_dir}/path_cat_list.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again make a header as above with _sed_ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "sed -i '1 i\\path:category' \"${root_dir}/path_cat_list.txt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:category\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/scan.c:kernel\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/core.h:mutex\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "head -n 3 $root_dir/path_cat_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "csvsql -d \":\" --db \"mysql://root:test@127.0.0.1/LinuxKernel\" --table \"categories\" --insert \"${root_dir}/path_cat_list.txt\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path\tcategory\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/scan.c\tkernel\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/core.h\tmutex\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/ibss.c\tetherdevice\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/nl80211.c\tif\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/linux-2.6.32.67/net/wireless/lib80211_crypt_tkip.c\terr\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mysql -uroot -ptest -e \"select * from categories limit 5;\" LinuxKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two tables so that the original inventory table has the categorical columns filled in."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "UPDATE inventory, categories\n",
    "SET inventory.cat = categories.category\n",
    "WHERE inventory.path = categories.path;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "sql=\"update inventory, categories set inventory.cat = categories.category where inventory.path = categories.path;\"\n",
    "\n",
    "mysql -uroot -ptest -e \"$sql\" LinuxKernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some summary output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ext  count(ext)  cat     count(cat)\n",
      "c    2930        module  2930\n",
      "c    2124        kernel  2124\n",
      "c    1271        init    1271\n",
      "h    875         types   875\n",
      "c    654         types   654\n",
      "c    299         delay   299\n",
      "c    282         errno   282\n",
      "c    200         fs      200\n",
      "c    185         sched   185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Errno 32] Broken pipe\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "sql2csv --db \"mysql://root:test@127.0.0.1/LinuxKernel\" --query \"select ext, count(ext), cat, count(cat) from inventory where ext = 'c' or ext = 'h' group by ext, cat order by count(cat) desc;\" | \\\n",
    "    head -n 10 | column -t -s,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the same thing with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "engine = sqlalchemy.create_engine(\"mysql://root:test@127.0.0.1/LinuxKernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instead of grepping we use the python regex in a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "ob = re.compile(\"#include\\s\\Wlinux/(?P<name>\\w+)\\.h\\W\")\n",
    "\n",
    "def regex_check(filename):\n",
    "    fname = path.join(root_dir, filename)\n",
    "    f = open(fname, 'r')\n",
    "    match = ob.search(f.read())\n",
    "    f.close()\n",
    "    \n",
    "    if match:\n",
    "        return match.group('name')\n",
    "    \n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the regex captures the right stuff. It only gets the first instance, which is fine. That's all the grep version above did. Not perfect, but OK for a day 1 iteration of what's in the directory we were given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#include <linux/rio.h>\n",
      "#include <linux/module.h>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "sed -n \"12,15p\" $root_dir/linux-2.6.32.67/drivers/rapidio/rio-access.c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rio\n"
     ]
    }
   ],
   "source": [
    "print regex_check('linux-2.6.32.67/drivers/rapidio/rio-access.c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "src = path.join(root_dir, \"linux_inventory.csv\")\n",
    "df = pd.read_csv(src, quotechar='\"', quoting=1)\n",
    "df['category'] = df.apply(lambda row: regex_check(row['path']) if row['ext'] == 'h' or row['ext'] == 'c' else None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>nlines</th>\n",
       "      <th>ext</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>1027</td>\n",
       "      <td>c</td>\n",
       "      <td>kernel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>401</td>\n",
       "      <td>h</td>\n",
       "      <td>mutex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>509</td>\n",
       "      <td>c</td>\n",
       "      <td>etherdevice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>4896</td>\n",
       "      <td>c</td>\n",
       "      <td>if</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>788</td>\n",
       "      <td>c</td>\n",
       "      <td>err</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>717</td>\n",
       "      <td>c</td>\n",
       "      <td>bitops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>679</td>\n",
       "      <td>c</td>\n",
       "      <td>kernel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>55</td>\n",
       "      <td>h</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>402</td>\n",
       "      <td>c</td>\n",
       "      <td>etherdevice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>113</td>\n",
       "      <td>c</td>\n",
       "      <td>device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/home/daniel/git/Python2.7/DataScience/command...</td>\n",
       "      <td>259</td>\n",
       "      <td>c</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 path  nlines ext     category\n",
       "0   /home/daniel/git/Python2.7/DataScience/command...    1027   c       kernel\n",
       "1   /home/daniel/git/Python2.7/DataScience/command...     401   h        mutex\n",
       "2   /home/daniel/git/Python2.7/DataScience/command...     509   c  etherdevice\n",
       "3   /home/daniel/git/Python2.7/DataScience/command...    4896   c           if\n",
       "4   /home/daniel/git/Python2.7/DataScience/command...     788   c          err\n",
       "5   /home/daniel/git/Python2.7/DataScience/command...     717   c       bitops\n",
       "6   /home/daniel/git/Python2.7/DataScience/command...     679   c       kernel\n",
       "7   /home/daniel/git/Python2.7/DataScience/command...      55   h         None\n",
       "8   /home/daniel/git/Python2.7/DataScience/command...     402   c  etherdevice\n",
       "9   /home/daniel/git/Python2.7/DataScience/command...     113   c       device\n",
       "10  /home/daniel/git/Python2.7/DataScience/command...     259   c         None"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0:10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't use Pandas' pivot table enough...I really like this tutorial and decided to incorporate it here.\n",
    "Once you go through the trouble of coding up a group by you might as well do a pivot table:\n",
    "\n",
    "http://pbpython.com/pandas-pivot-table-explained.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>ext</th>\n",
       "      <th>nlines</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ext</th>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">c</th>\n",
       "      <th>sched</th>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>137675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>errno</th>\n",
       "      <td>283</td>\n",
       "      <td>283</td>\n",
       "      <td>147777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fs</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>157690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <th>types</th>\n",
       "      <td>881</td>\n",
       "      <td>881</td>\n",
       "      <td>191313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">c</th>\n",
       "      <th>delay</th>\n",
       "      <td>305</td>\n",
       "      <td>305</td>\n",
       "      <td>288431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>types</th>\n",
       "      <td>655</td>\n",
       "      <td>655</td>\n",
       "      <td>325444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init</th>\n",
       "      <td>1277</td>\n",
       "      <td>1277</td>\n",
       "      <td>618232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kernel</th>\n",
       "      <td>2124</td>\n",
       "      <td>2124</td>\n",
       "      <td>1103586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>module</th>\n",
       "      <td>2941</td>\n",
       "      <td>2941</td>\n",
       "      <td>2237201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <th></th>\n",
       "      <td>30485</td>\n",
       "      <td>30485</td>\n",
       "      <td>10973169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category    ext    nlines\n",
       "ext category                           \n",
       "c   sched          186    186    137675\n",
       "    errno          283    283    147777\n",
       "    fs             200    200    157690\n",
       "h   types          881    881    191313\n",
       "c   delay          305    305    288431\n",
       "    types          655    655    325444\n",
       "    init          1277   1277    618232\n",
       "    kernel        2124   2124   1103586\n",
       "    module        2941   2941   2237201\n",
       "All              30485  30485  10973169"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = df.pivot_table(index=['ext', 'category'], \\\n",
    "                       aggfunc={'ext':len, 'category':len, 'nlines':np.sum}, \\\n",
    "                       values=['ext', 'category', 'nlines'], \\\n",
    "                       margins=True)\n",
    "                      \n",
    "table.sort(\"nlines\")[-10:]                                                   \n",
    "\n",
    "#table = df.pivot_table(index='ext', aggfunc={'nlines':np.sum,'ext':np.count_nonzero}, values=['nlines', 'ext'], margins=True)\n",
    "#table.sort(\"nlines\")[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump data frame to mySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_sql(\"inventory2\", engine, flavor='mysql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "sql=\"select count(path) as cts, category from inventory2 group by category order by cts desc limit 10;\"\n",
    "mysql -uroot -ptest -e \"${sql}\" LinuxKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "sql2csv --db \"mysql://root:test@127.0.0.1/LinuxKernel\" --query \"select count(path) as cts, category from inventory2 group by category order by cts desc;\" \\\n",
    "> \"${root_dir}/categories.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Command line\n",
    "\n",
    "## Save the output to a file for the future\n",
    "We'll redirect the output from standard out (terminal display) to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "cat $root_dir/linux_inventory.csv | cut -d, -f 3 | sort | uniq -c | sort -n > $root_dir/ext_list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Makefile\n",
    "Let's try using a makefile. We have 2 steps required to create the sorted list of extensions and their counts.\n",
    "\n",
    "1. make an inventory\n",
    "2. sort the inventory by extension\n",
    "\n",
    "We also have 2 dependencies\n",
    "\n",
    "1. Linux kernel source\n",
    "2. inventory\n",
    "\n",
    "There's one final output, the sorted list of counts by extension\n",
    "\n",
    "The idea behind the makefile, is that if we change a dependency, then we want the target output steps to run again.\n",
    "If a file was added to the Linux kernel, then we need a new inventory and then a file extension count list. in the a real world usage I'd make some more effort to avoid running the entire inventory. Here, that's a bit overkill.\n",
    "\n",
    "\n",
    "## What is happening\n",
    "Make keeps track of when a file or directory has been modified. If something was touched, then the recipe is invoked to handle that updated information. Make can make use of functions, shell paramters although it a slightly different form.\n",
    "\n",
    "Makefile are typically named, \"makefile\", and are tab delimited. Make has to parse the makefile so there's some special syntax that is similar to but distinct from that of the shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_data\"\n",
    "\n",
    "cat -n makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_data\"\n",
    "cat -n $root_dir/makefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test it out\n",
    "\n",
    "We can use the _touch_ command to update the modifcation dates of a file or directory.\n",
    "There are at least 3 ways to see the modifcation dates of a file, the most common being to _stat_. incidentaly, _stat_ is a really basic program that is called internally in many other shell programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_data\"\n",
    "\n",
    "stat $root_dir/linux-2.6.32.67"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program _touch_ is used to update the modification time to the present date. It is also used to create an empty file when one needs such a thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_data\"\n",
    "\n",
    "touch $root_dir/linux-2.6.32.67\n",
    "stat $root_dir/linux-2.6.32.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_data\"\n",
    "# if we are in the directory where the makefile exists, just issue the _make_ command\n",
    "# because this notebook could theoretically be run from anywhere, I'm using the full path and the -f option\n",
    "make -f $root_dir/makefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_data\"\n",
    "\n",
    "stat $root_dir/ext_list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the output of command to a variable (shell paramter)\n",
    "\n",
    "We can set a shell paramter from the output of another shell command/program.\n",
    "You've seen this trick used in the simple inventory program earlier. I used it a lot actually, to \n",
    "assign the output of commands to a shell paramter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo $SHELL # shell variable setup when you login\n",
    "var=$(echo $SHELL | cut -d/ -f 2)\n",
    "echo $var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example with the _date_ program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_data\"\n",
    "\n",
    "dir_path=${root_dir}/$(date +%Y_%m_%d_%H:%M:%S) # date can take a format string\n",
    "echo $dir_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shell Loops\n",
    "\n",
    "There are two kinds of loops that I tend to use:\n",
    "\n",
    "1. while\n",
    "2. for\n",
    "\n",
    "### Tests\n",
    "\n",
    "The square brackets are called \"tests\" . This is another topic in shell scripting that I can't really cover right here but you can see a use case for it. \n",
    "\n",
    "The loop below is rather contrived. We would really just use _cat_ command to see the contents. But it's a good practice because the output is predictable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \"1992-1997\"\n",
      "1 \"1994-2004\"\n",
      "1 \"1995-2002\"\n",
      "1 \"1996-2002\"\n",
      "1 \"278\"\n",
      "1 \"5\"\n",
      "1 \"act2000\"\n",
      "1 \"AddingFirmware\"\n",
      "1 \"AdvancedTopics\"\n",
      "1 \"agh\"\n",
      "1 \"aic79xx\"\n",
      "1 \"aic7xxx\"\n",
      "1 \"arcmsr\"\n",
      "1 \"asp\"\n",
      "1 \"au0828\"\n",
      "1 \"audio\"\n",
      "1 \"auto\"\n",
      "1 \"avmb1\"\n",
      "1 \"awk\"\n",
      "1 \"ax\"\n",
      "1 \"binfmt\"\n",
      "1 \"bttv\"\n",
      "1 \"buddha\"\n",
      "1 \"build\"\n",
      "1 \"CAPI\"\n",
      "1 \"cc\"\n",
      "1 \"cert\"\n",
      "1 \"ChangeLog\"\n",
      "1 \"char\"\n",
      "1 \"clean\"\n",
      "1 \"Coding\"\n",
      "1 \"common\"\n",
      "1 \"concap\"\n",
      "1 \"Conclusion\"\n",
      "1 \"copyright\"\n",
      "1 \"cpia\"\n",
      "1 \"cpia2\"\n",
      "1 \"cputype\"\n",
      "1 \"cx23885\"\n",
      "1 \"cycladesZ\"\n",
      "1 \"DAC960\"\n",
      "1 \"dino\"\n",
      "1 \"diversion\"\n",
      "1 \"DOC\"\n",
      "1 \"drm\"\n",
      "1 \"drv_ba_resend\"\n",
      "1 \"dtc\"\n",
      "1 \"dvb-usb\"\n",
      "1 \"Early-stage\"\n",
      "1 \"em28xx\"\n",
      "1 \"ext\"\n",
      "1 \"FIRST\"\n",
      "1 \"FlashPoint\"\n",
      "1 \"Followthrough\"\n",
      "1 \"FPE\"\n",
      "1 \"freeze\"\n",
      "1 \"freezer\"\n",
      "1 \"fwinst\"\n",
      "1 \"gate\"\n",
      "1 \"gdbinit_200MHz_16MB\"\n",
      "1 \"gdbinit_300MHz_32MB\"\n",
      "1 \"gdbinit_400MHz_32MB\"\n",
      "1 \"generic\"\n",
      "1 \"gigaset\"\n",
      "1 \"glade\"\n",
      "1 \"headersinst\"\n",
      "1 \"hfc-pci\"\n",
      "1 \"HiSax\"\n",
      "1 \"history\"\n",
      "1 \"hm12\"\n",
      "1 \"host\"\n",
      "1 \"hp300\"\n",
      "1 \"hysdn\"\n",
      "1 \"hz\"\n",
      "1 \"i2400m\"\n",
      "1 \"icn\"\n",
      "1 \"ide\"\n",
      "1 \"include\"\n",
      "1 \"inc_shipped\"\n",
      "1 \"inf\"\n",
      "1 \"ini\"\n",
      "1 \"Intro\"\n",
      "1 \"ioctl\"\n",
      "1 \"iosched\"\n",
      "1 \"ips\"\n",
      "1 \"ipw2100\"\n",
      "1 \"ipw2200\"\n",
      "1 \"ir\"\n",
      "1 \"kgdb\"\n",
      "1 \"kmemcheck\"\n",
      "1 \"lib\"\n",
      "1 \"LIB\"\n",
      "1 \"libfdt\"\n",
      "1 \"Locking\"\n",
      "1 \"lpfc\"\n",
      "1 \"mailmap\"\n",
      "1 \"maya44\"\n",
      "1 \"megaraid_sas\"\n",
      "1 \"mISDN\"\n",
      "1 \"mm\"\n",
      "1 \"modes\"\n",
      "1 \"modinst\"\n",
      "1 \"modpost\"\n",
      "1 \"modules\"\n",
      "1 \"ncr53c8xx\"\n",
      "1 \"net\"\n",
      "1 \"netlink\"\n",
      "1 \"nommu_defconfig\"\n",
      "1 \"normal\"\n",
      "1 \"opsp_defconfig\"\n",
      "1 \"OSS\"\n",
      "1 \"pcbit\"\n",
      "1 \"platform\"\n",
      "1 \"png\"\n",
      "1 \"Posting\"\n",
      "1 \"preempt\"\n",
      "1 \"Process\"\n",
      "1 \"pvrusb2\"\n",
      "1 \"qla2xxx\"\n",
      "1 \"qla3xxx\"\n",
      "1 \"qlge\"\n",
      "1 \"quirks\"\n",
      "1 \"README\"\n",
      "1 \"rest\"\n",
      "1 \"rules\"\n",
      "1 \"saa7164\"\n",
      "1 \"sb1000\"\n",
      "1 \"sc\"\n",
      "1 \"sed\"\n",
      "1 \"smp\"\n",
      "1 \"SRC\"\n",
      "1 \"sym53c8xx\"\n",
      "1 \"sym53c8xx_2\"\n",
      "1 \"syncppp\"\n",
      "1 \"tex\"\n",
      "1 \"tuner\"\n",
      "1 \"um\"\n",
      "1 \"uni\"\n",
      "1 \"usbvision\"\n",
      "1 \"vbi\"\n",
      "1 \"vdec2\"\n",
      "1 \"vdec2_defconfig\"\n",
      "1 \"vim\"\n",
      "1 \"WARNING\"\n",
      "1 \"wimax\"\n",
      "1 \"WINVIEW\"\n",
      "1 \"x25\"\n",
      "1 \"x86\"\n",
      "1 \"ymfsb\"\n",
      "2 \"asm\"\n",
      "2 \"cx88\"\n",
      "2 \"dat\"\n",
      "2 \"FAQ\"\n",
      "2 \"fax\"\n",
      "2 \"fig\"\n",
      "2 \"gperf\"\n",
      "2 \"html\"\n",
      "2 \"ids\"\n",
      "2 \"inl\"\n",
      "2 \"ivtv\"\n",
      "2 \"megaraid\"\n",
      "2 \"mk\"\n",
      "2 \"nommu\"\n",
      "2 \"pbm\"\n",
      "2 \"saa7134\"\n",
      "2 \"ucode\"\n",
      "2 \"up_defconfig\"\n",
      "3 \"gdbinit\"\n",
      "3 \"map\"\n",
      "3 \"py\"\n",
      "3 \"reg\"\n",
      "3 \"seq\"\n",
      "3 \"smp_defconfig\"\n",
      "4 \"cpu\"\n",
      "4 \"doc\"\n",
      "4 \"in\"\n",
      "4 \"inc\"\n",
      "4 \"ld\"\n",
      "4 \"uc\"\n",
      "5 \"l\"\n",
      "5 \"scr\"\n",
      "5 \"y\"\n",
      "6 \"conf\"\n",
      "6 \"xsl\"\n",
      "7 \"gif\"\n",
      "7 \"H16\"\n",
      "7 \"pdf\"\n",
      "7 \"sa\"\n",
      "9 \"h_shipped\"\n",
      "11 \"c_shipped\"\n",
      "13 \"tst\"\n",
      "14 \"ppm\"\n",
      "15 \"lds\"\n",
      "23 \"pl\"\n",
      "26 \"HEX\"\n",
      "28 \"debug\"\n",
      "33 \"tmpl\"\n",
      "34 \"sh\"\n",
      "50 \"boot\"\n",
      "79 \"gitignore\"\n",
      "105 \"xml\"\n",
      "111 \"ihex\"\n",
      "115 \"dts\"\n",
      "857 \"txt\"\n",
      "1080 \"S\"\n",
      "2818 \"NONE\"\n",
      "11638 \"h\"\n",
      "13154 \"c\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "while read f;do\n",
    "    echo $f\n",
    "done < $root_dir/ext_list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bash will delimit the output of the cat, by spaces or newlines (\\n). So in order to get the output\n",
    "as we'd like, we need each line to be delimited by \\n, thus the IFS syntax.\n",
    "\n",
    "Read is a better way to work with the contents of a file where it's assumed that you want data on a per-line basis.\n",
    "Most of the time we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1 \"1992-1997\"\n",
      "      1 \"1994-2004\"\n",
      "      1 \"1995-2002\"\n",
      "      1 \"1996-2002\"\n",
      "      1 \"278\"\n",
      "      1 \"5\"\n",
      "      1 \"act2000\"\n",
      "      1 \"AddingFirmware\"\n",
      "      1 \"AdvancedTopics\"\n",
      "      1 \"agh\"\n",
      "      1 \"aic79xx\"\n",
      "      1 \"aic7xxx\"\n",
      "      1 \"arcmsr\"\n",
      "      1 \"asp\"\n",
      "      1 \"au0828\"\n",
      "      1 \"audio\"\n",
      "      1 \"auto\"\n",
      "      1 \"avmb1\"\n",
      "      1 \"awk\"\n",
      "      1 \"ax\"\n",
      "      1 \"binfmt\"\n",
      "      1 \"bttv\"\n",
      "      1 \"buddha\"\n",
      "      1 \"build\"\n",
      "      1 \"CAPI\"\n",
      "      1 \"cc\"\n",
      "      1 \"cert\"\n",
      "      1 \"ChangeLog\"\n",
      "      1 \"char\"\n",
      "      1 \"clean\"\n",
      "      1 \"Coding\"\n",
      "      1 \"common\"\n",
      "      1 \"concap\"\n",
      "      1 \"Conclusion\"\n",
      "      1 \"copyright\"\n",
      "      1 \"cpia\"\n",
      "      1 \"cpia2\"\n",
      "      1 \"cputype\"\n",
      "      1 \"cx23885\"\n",
      "      1 \"cycladesZ\"\n",
      "      1 \"DAC960\"\n",
      "      1 \"dino\"\n",
      "      1 \"diversion\"\n",
      "      1 \"DOC\"\n",
      "      1 \"drm\"\n",
      "      1 \"drv_ba_resend\"\n",
      "      1 \"dtc\"\n",
      "      1 \"dvb-usb\"\n",
      "      1 \"Early-stage\"\n",
      "      1 \"em28xx\"\n",
      "      1 \"ext\"\n",
      "      1 \"FIRST\"\n",
      "      1 \"FlashPoint\"\n",
      "      1 \"Followthrough\"\n",
      "      1 \"FPE\"\n",
      "      1 \"freeze\"\n",
      "      1 \"freezer\"\n",
      "      1 \"fwinst\"\n",
      "      1 \"gate\"\n",
      "      1 \"gdbinit_200MHz_16MB\"\n",
      "      1 \"gdbinit_300MHz_32MB\"\n",
      "      1 \"gdbinit_400MHz_32MB\"\n",
      "      1 \"generic\"\n",
      "      1 \"gigaset\"\n",
      "      1 \"glade\"\n",
      "      1 \"headersinst\"\n",
      "      1 \"hfc-pci\"\n",
      "      1 \"HiSax\"\n",
      "      1 \"history\"\n",
      "      1 \"hm12\"\n",
      "      1 \"host\"\n",
      "      1 \"hp300\"\n",
      "      1 \"hysdn\"\n",
      "      1 \"hz\"\n",
      "      1 \"i2400m\"\n",
      "      1 \"icn\"\n",
      "      1 \"ide\"\n",
      "      1 \"include\"\n",
      "      1 \"inc_shipped\"\n",
      "      1 \"inf\"\n",
      "      1 \"ini\"\n",
      "      1 \"Intro\"\n",
      "      1 \"ioctl\"\n",
      "      1 \"iosched\"\n",
      "      1 \"ips\"\n",
      "      1 \"ipw2100\"\n",
      "      1 \"ipw2200\"\n",
      "      1 \"ir\"\n",
      "      1 \"kgdb\"\n",
      "      1 \"kmemcheck\"\n",
      "      1 \"lib\"\n",
      "      1 \"LIB\"\n",
      "      1 \"libfdt\"\n",
      "      1 \"Locking\"\n",
      "      1 \"lpfc\"\n",
      "      1 \"mailmap\"\n",
      "      1 \"maya44\"\n",
      "      1 \"megaraid_sas\"\n",
      "      1 \"mISDN\"\n",
      "      1 \"mm\"\n",
      "      1 \"modes\"\n",
      "      1 \"modinst\"\n",
      "      1 \"modpost\"\n",
      "      1 \"modules\"\n",
      "      1 \"ncr53c8xx\"\n",
      "      1 \"net\"\n",
      "      1 \"netlink\"\n",
      "      1 \"nommu_defconfig\"\n",
      "      1 \"normal\"\n",
      "      1 \"opsp_defconfig\"\n",
      "      1 \"OSS\"\n",
      "      1 \"pcbit\"\n",
      "      1 \"platform\"\n",
      "      1 \"png\"\n",
      "      1 \"Posting\"\n",
      "      1 \"preempt\"\n",
      "      1 \"Process\"\n",
      "      1 \"pvrusb2\"\n",
      "      1 \"qla2xxx\"\n",
      "      1 \"qla3xxx\"\n",
      "      1 \"qlge\"\n",
      "      1 \"quirks\"\n",
      "      1 \"README\"\n",
      "      1 \"rest\"\n",
      "      1 \"rules\"\n",
      "      1 \"saa7164\"\n",
      "      1 \"sb1000\"\n",
      "      1 \"sc\"\n",
      "      1 \"sed\"\n",
      "      1 \"smp\"\n",
      "      1 \"SRC\"\n",
      "      1 \"sym53c8xx\"\n",
      "      1 \"sym53c8xx_2\"\n",
      "      1 \"syncppp\"\n",
      "      1 \"tex\"\n",
      "      1 \"tuner\"\n",
      "      1 \"um\"\n",
      "      1 \"uni\"\n",
      "      1 \"usbvision\"\n",
      "      1 \"vbi\"\n",
      "      1 \"vdec2\"\n",
      "      1 \"vdec2_defconfig\"\n",
      "      1 \"vim\"\n",
      "      1 \"WARNING\"\n",
      "      1 \"wimax\"\n",
      "      1 \"WINVIEW\"\n",
      "      1 \"x25\"\n",
      "      1 \"x86\"\n",
      "      1 \"ymfsb\"\n",
      "      2 \"asm\"\n",
      "      2 \"cx88\"\n",
      "      2 \"dat\"\n",
      "      2 \"FAQ\"\n",
      "      2 \"fax\"\n",
      "      2 \"fig\"\n",
      "      2 \"gperf\"\n",
      "      2 \"html\"\n",
      "      2 \"ids\"\n",
      "      2 \"inl\"\n",
      "      2 \"ivtv\"\n",
      "      2 \"megaraid\"\n",
      "      2 \"mk\"\n",
      "      2 \"nommu\"\n",
      "      2 \"pbm\"\n",
      "      2 \"saa7134\"\n",
      "      2 \"ucode\"\n",
      "      2 \"up_defconfig\"\n",
      "      3 \"gdbinit\"\n",
      "      3 \"map\"\n",
      "      3 \"py\"\n",
      "      3 \"reg\"\n",
      "      3 \"seq\"\n",
      "      3 \"smp_defconfig\"\n",
      "      4 \"cpu\"\n",
      "      4 \"doc\"\n",
      "      4 \"in\"\n",
      "      4 \"inc\"\n",
      "      4 \"ld\"\n",
      "      4 \"uc\"\n",
      "      5 \"l\"\n",
      "      5 \"scr\"\n",
      "      5 \"y\"\n",
      "      6 \"conf\"\n",
      "      6 \"xsl\"\n",
      "      7 \"gif\"\n",
      "      7 \"H16\"\n",
      "      7 \"pdf\"\n",
      "      7 \"sa\"\n",
      "      9 \"h_shipped\"\n",
      "     11 \"c_shipped\"\n",
      "     13 \"tst\"\n",
      "     14 \"ppm\"\n",
      "     15 \"lds\"\n",
      "     23 \"pl\"\n",
      "     26 \"HEX\"\n",
      "     28 \"debug\"\n",
      "     33 \"tmpl\"\n",
      "     34 \"sh\"\n",
      "     50 \"boot\"\n",
      "     79 \"gitignore\"\n",
      "    105 \"xml\"\n",
      "    111 \"ihex\"\n",
      "    115 \"dts\"\n",
      "    857 \"txt\"\n",
      "   1080 \"S\"\n",
      "   2818 \"NONE\"\n",
      "  11638 \"h\"\n",
      "  13154 \"c\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "IFS=$'\\n'\n",
    "for f in $(cat $root_dir/ext_list.txt);do                                                                                 \n",
    "    echo $f\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do something slighly more interesting and introduce the _test_ while were at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 \"c_shipped\"\n",
      "13 \"tst\"\n",
      "14 \"ppm\"\n",
      "15 \"lds\"\n",
      "23 \"pl\"\n",
      "26 \"HEX\"\n",
      "28 \"debug\"\n",
      "33 \"tmpl\"\n",
      "34 \"sh\"\n",
      "50 \"boot\"\n",
      "79 \"gitignore\"\n",
      "105 \"xml\"\n",
      "111 \"ihex\"\n",
      "115 \"dts\"\n",
      "857 \"txt\"\n",
      "1080 \"S\"\n",
      "2818 \"NONE\"\n",
      "11638 \"h\"\n",
      "13154 \"c\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "while read f;do\n",
    "        count=$(echo $f | awk '{print $1}')\n",
    "    if [ $count -gt 10 ];then\n",
    "        echo $f\n",
    "    fi\n",
    "done < $root_dir/ext_list.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use case\n",
    "Maybe you run a program in a loop, and save each output to a new file named with the dat and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/2015_09_30_19:07:04.test\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/2015_09_30_19:07:04.test\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/2015_09_30_19:07:04.test\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/2015_09_30_19:07:04.test\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/2015_09_30_19:07:04.test\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "for ind in {1..5};do \n",
    "    fname=\"${root_dir}/$(date +%Y_%m_%d_%H:%M:%S).test\"\n",
    "    echo $fname\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/test_1.txt\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/test_2.txt\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/test_3.txt\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/test_4.txt\n",
      "/home/daniel/git/Python2.7/DataScience/command_line_pres_data/test_5.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "root_dir=\"/home/daniel/git/Python2.7/DataScience/command_line_pres_data\"\n",
    "\n",
    "for ind in {1..5};do \n",
    "    fname=\"${root_dir}/test_$ind.txt\"\n",
    "    echo $fname\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# You made it pretty damned far.... I've run out of things to cram into this tutorial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
